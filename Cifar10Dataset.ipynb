{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10Dataset",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#imports and downloading dataset\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXpwI_tdPcCZ",
        "outputId": "a0becfcb-249d-47c7-c764-6b39b2b7e1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1QDMbYlQPrL",
        "outputId": "b3a76407-221e-4fb1-b7fc-70aed1bacad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshaping and preparing for model\n",
        "x_train = ((x_train.reshape(x_train.shape[0], 32, 32, 3)).astype('float32')) / 255\n",
        "x_test = ((x_test.reshape(x_test.shape[0], 32, 32, 3)).astype('float32')) / 255\n",
        "input_shape = (32, 32, 3)\n",
        "print(\"x_train\", x_train.shape)\n",
        "print(\"x_test\", x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZZ1rUlHPo37",
        "outputId": "d73f440a-ab71-4144-8362-f2f39a5edde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train (50000, 32, 32, 3)\n",
            "x_test (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model imports\n",
        "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Dropout, Dense, MaxPooling2D, Attention\n",
        "from tensorflow.keras.regularizers import l1_l2, l1, l2"
      ],
      "metadata": {
        "id": "aTrxEVvzQp7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the model\n",
        "def build_model(input_shape):\n",
        "\n",
        "    model = Sequential()\n",
        "        \n",
        "    model.add(Conv2D(256, kernel_size=(4, 4), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, kernel_size=(4, 4), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(BatchNormalization())        \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "        \n",
        "    model.add(Conv2D(1024, kernel_size=(2, 2), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(1024, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(BatchNormalization())    \n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    model.add(Conv2D(2048, kernel_size=(2, 2), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(2048, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(BatchNormalization())    \n",
        "\n",
        "\n",
        "    model.add(Flatten())\n",
        "        \n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "        \n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    \n",
        "    \n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "  \n",
        "import tensorflow\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "variable_learning_rate = ReduceLROnPlateau(monitor='val_accuracy', factor=0.9, patience=2)\n",
        "                          \n",
        "                          \n",
        "\n",
        "model = build_model(input_shape=input_shape)\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJeqJpIQRGFc",
        "outputId": "c36635df-f108-4e98-a8c8-e2ee99559a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 256)       12544     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 256)      1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 256)       1048832   \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 29, 29, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 256)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 256)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 12, 12, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 6, 6, 1024)        2098176   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 6, 6, 1024)       4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 5, 5, 1024)        4195328   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 5, 5, 1024)       4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 1024)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 1024)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 2, 2, 2048)        8390656   \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 2, 2, 2048)       8192      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 2, 2048)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 1, 1, 2048)        16779264  \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 1, 1, 2048)       8192      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,852,362\n",
            "Trainable params: 38,837,002\n",
            "Non-trainable params: 15,360\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training and testing the model's accuracy\n",
        "model.fit(x_train, y_train, epochs=40, batch_size=1024, validation_data=(x_test, y_test), callbacks=variable_learning_rate)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG8L2aRqSwNq",
        "outputId": "64429c1c-e012-4158-e525-4458416e73a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "391/391 [==============================] - 209s 497ms/step - loss: 1.7332 - accuracy: 0.3660 - val_loss: 2.3470 - val_accuracy: 0.1629 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "391/391 [==============================] - 184s 471ms/step - loss: 1.2094 - accuracy: 0.5739 - val_loss: 1.3200 - val_accuracy: 0.5306 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "391/391 [==============================] - 184s 471ms/step - loss: 0.9761 - accuracy: 0.6611 - val_loss: 1.4513 - val_accuracy: 0.5539 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "391/391 [==============================] - 183s 469ms/step - loss: 0.8284 - accuracy: 0.7168 - val_loss: 1.1474 - val_accuracy: 0.6275 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "391/391 [==============================] - 183s 469ms/step - loss: 0.7248 - accuracy: 0.7563 - val_loss: 0.7339 - val_accuracy: 0.7567 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "391/391 [==============================] - 183s 469ms/step - loss: 0.6336 - accuracy: 0.7903 - val_loss: 0.6472 - val_accuracy: 0.7901 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "391/391 [==============================] - 183s 468ms/step - loss: 0.5702 - accuracy: 0.8135 - val_loss: 0.6372 - val_accuracy: 0.7856 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "391/391 [==============================] - 183s 468ms/step - loss: 0.5120 - accuracy: 0.8314 - val_loss: 0.6741 - val_accuracy: 0.7752 - lr: 0.0010\n",
            "Epoch 9/40\n",
            "391/391 [==============================] - 183s 467ms/step - loss: 0.4441 - accuracy: 0.8556 - val_loss: 0.5679 - val_accuracy: 0.8099 - lr: 9.0000e-04\n",
            "Epoch 10/40\n",
            "391/391 [==============================] - 183s 467ms/step - loss: 0.4040 - accuracy: 0.8687 - val_loss: 0.6340 - val_accuracy: 0.8063 - lr: 9.0000e-04\n",
            "Epoch 11/40\n",
            "391/391 [==============================] - 183s 468ms/step - loss: 0.3721 - accuracy: 0.8781 - val_loss: 0.5491 - val_accuracy: 0.8220 - lr: 9.0000e-04\n",
            "Epoch 12/40\n",
            "391/391 [==============================] - 183s 467ms/step - loss: 0.3400 - accuracy: 0.8903 - val_loss: 0.6428 - val_accuracy: 0.7981 - lr: 9.0000e-04\n",
            "Epoch 13/40\n",
            "391/391 [==============================] - 183s 467ms/step - loss: 0.3123 - accuracy: 0.8976 - val_loss: 0.4753 - val_accuracy: 0.8558 - lr: 9.0000e-04\n",
            "Epoch 14/40\n",
            "391/391 [==============================] - 184s 472ms/step - loss: 0.2869 - accuracy: 0.9069 - val_loss: 0.5002 - val_accuracy: 0.8487 - lr: 9.0000e-04\n",
            "Epoch 15/40\n",
            "391/391 [==============================] - 183s 467ms/step - loss: 0.2691 - accuracy: 0.9137 - val_loss: 0.5725 - val_accuracy: 0.8245 - lr: 9.0000e-04\n",
            "Epoch 16/40\n",
            "391/391 [==============================] - 183s 467ms/step - loss: 0.2329 - accuracy: 0.9249 - val_loss: 0.4916 - val_accuracy: 0.8591 - lr: 8.1000e-04\n",
            "Epoch 17/40\n",
            "391/391 [==============================] - 182s 467ms/step - loss: 0.2012 - accuracy: 0.9366 - val_loss: 0.5536 - val_accuracy: 0.8477 - lr: 8.1000e-04\n",
            "Epoch 18/40\n",
            "391/391 [==============================] - 183s 467ms/step - loss: 0.1908 - accuracy: 0.9389 - val_loss: 0.5047 - val_accuracy: 0.8510 - lr: 8.1000e-04\n",
            "Epoch 19/40\n",
            "391/391 [==============================] - 184s 471ms/step - loss: 0.1641 - accuracy: 0.9459 - val_loss: 0.4936 - val_accuracy: 0.8592 - lr: 7.2900e-04\n",
            "Epoch 20/40\n",
            "391/391 [==============================] - 182s 466ms/step - loss: 0.1519 - accuracy: 0.9509 - val_loss: 0.5688 - val_accuracy: 0.8457 - lr: 7.2900e-04\n",
            "Epoch 21/40\n",
            "391/391 [==============================] - 182s 466ms/step - loss: 0.1420 - accuracy: 0.9542 - val_loss: 0.6466 - val_accuracy: 0.8390 - lr: 7.2900e-04\n",
            "Epoch 22/40\n",
            "391/391 [==============================] - 180s 459ms/step - loss: 0.1279 - accuracy: 0.9583 - val_loss: 0.5213 - val_accuracy: 0.8674 - lr: 6.5610e-04\n",
            "Epoch 23/40\n",
            "391/391 [==============================] - 181s 464ms/step - loss: 0.1151 - accuracy: 0.9626 - val_loss: 0.5674 - val_accuracy: 0.8563 - lr: 6.5610e-04\n",
            "Epoch 24/40\n",
            "391/391 [==============================] - 180s 459ms/step - loss: 0.1044 - accuracy: 0.9661 - val_loss: 0.5145 - val_accuracy: 0.8698 - lr: 6.5610e-04\n",
            "Epoch 25/40\n",
            " 73/391 [====>.........................] - ETA: 2:19 - loss: 0.1013 - accuracy: 0.9688"
          ]
        }
      ]
    }
  ]
}