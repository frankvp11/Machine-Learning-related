{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vnsYJcUNdX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05eb28fa-ae2b-46a4-84fa-084e94d3831d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#basic imports\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BufE0Q2mN-LL",
        "outputId": "3e65165b-56d2-4cc5-d74e-c24477c67553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnfEltL1OoVE",
        "outputId": "9c5d8baa-af10-4437-82d2-c6227bfba9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "Number of images in x_train 60000\n",
            "Number of images in x_test 10000\n"
          ]
        }
      ],
      "source": [
        "#pipelining the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('Number of images in x_train', x_train.shape[0])\n",
        "print('Number of images in x_test', x_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bolz7LBouV0f"
      },
      "outputs": [],
      "source": [
        "#model imports\n",
        "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Dropout, Dense, MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l1_l2, l1, l2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape):\n",
        "\n",
        "    \n",
        "    model = Sequential([\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "\n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "        BatchNormalization(),        \n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.3),\n",
        "        \n",
        "        Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(512, kernel_size=(3, 3), activation='relu'),\n",
        "        BatchNormalization(),    \n",
        "        MaxPooling2D(pool_size=(2, 2)),   \n",
        "        Dropout(0.3),\n",
        "        \n",
        "        Flatten(),\n",
        "        \n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(512, activation='relu'),\n",
        "        \n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "  \n",
        "import tensorflow\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "variable_learning_rate = ReduceLROnPlateau(monitor='val_accuracy', factor=0.9, patience=2)\n",
        "                          \n",
        "                          \n",
        "\n",
        "model = build_model(input_shape=input_shape)\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuQ_o726lHa3",
        "outputId": "fbe9453d-5fee-4f79-dce4-fd460fa81c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 26, 26, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 13, 13, 128)       36992     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 13, 13, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 11, 11, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 5, 128)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 512)         590336    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 5, 5, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 3, 3, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              525312    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,204,906\n",
            "Trainable params: 4,202,218\n",
            "Non-trainable params: 2,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model training and testing\n",
        "model.fit(x_train, y_train, epochs=70, validation_data=(x_test, y_test), batch_size=128, callbacks=[variable_learning_rate])\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVh2V3N2lKCP",
        "outputId": "9e0e2322-bad9-49c6-cba5-d445d5af01e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "469/469 [==============================] - 49s 77ms/step - loss: 0.1689 - accuracy: 0.9484 - val_loss: 0.1671 - val_accuracy: 0.9471 - lr: 0.0010\n",
            "Epoch 2/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0569 - accuracy: 0.9834 - val_loss: 0.0237 - val_accuracy: 0.9921 - lr: 0.0010\n",
            "Epoch 3/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0425 - accuracy: 0.9876 - val_loss: 0.0360 - val_accuracy: 0.9883 - lr: 0.0010\n",
            "Epoch 4/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0378 - accuracy: 0.9894 - val_loss: 0.0246 - val_accuracy: 0.9922 - lr: 0.0010\n",
            "Epoch 5/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0321 - accuracy: 0.9908 - val_loss: 0.0261 - val_accuracy: 0.9925 - lr: 0.0010\n",
            "Epoch 6/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0317 - val_accuracy: 0.9918 - lr: 0.0010\n",
            "Epoch 7/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.0303 - val_accuracy: 0.9897 - lr: 0.0010\n",
            "Epoch 8/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.0244 - val_accuracy: 0.9929 - lr: 9.0000e-04\n",
            "Epoch 9/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0240 - val_accuracy: 0.9936 - lr: 9.0000e-04\n",
            "Epoch 10/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0508 - val_accuracy: 0.9902 - lr: 9.0000e-04\n",
            "Epoch 11/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.0329 - val_accuracy: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 12/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.0267 - val_accuracy: 0.9925 - lr: 8.1000e-04\n",
            "Epoch 13/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.0240 - val_accuracy: 0.9946 - lr: 8.1000e-04\n",
            "Epoch 14/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.0255 - val_accuracy: 0.9923 - lr: 8.1000e-04\n",
            "Epoch 15/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.0304 - val_accuracy: 0.9926 - lr: 8.1000e-04\n",
            "Epoch 16/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0190 - val_accuracy: 0.9952 - lr: 7.2900e-04\n",
            "Epoch 17/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0217 - val_accuracy: 0.9944 - lr: 7.2900e-04\n",
            "Epoch 18/70\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0279 - val_accuracy: 0.9935 - lr: 7.2900e-04\n",
            "Epoch 19/70\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.0289 - val_accuracy: 0.9931 - lr: 6.5610e-04\n",
            "Epoch 20/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0200 - val_accuracy: 0.9944 - lr: 6.5610e-04\n",
            "Epoch 21/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0226 - val_accuracy: 0.9950 - lr: 5.9049e-04\n",
            "Epoch 22/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0215 - val_accuracy: 0.9950 - lr: 5.9049e-04\n",
            "Epoch 23/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0204 - val_accuracy: 0.9953 - lr: 5.3144e-04\n",
            "Epoch 24/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0239 - val_accuracy: 0.9955 - lr: 5.3144e-04\n",
            "Epoch 25/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0193 - val_accuracy: 0.9962 - lr: 5.3144e-04\n",
            "Epoch 26/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0224 - val_accuracy: 0.9957 - lr: 5.3144e-04\n",
            "Epoch 27/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0372 - val_accuracy: 0.9932 - lr: 5.3144e-04\n",
            "Epoch 28/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0203 - val_accuracy: 0.9956 - lr: 4.7830e-04\n",
            "Epoch 29/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0203 - val_accuracy: 0.9960 - lr: 4.7830e-04\n",
            "Epoch 30/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0275 - val_accuracy: 0.9949 - lr: 4.3047e-04\n",
            "Epoch 31/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0233 - val_accuracy: 0.9960 - lr: 4.3047e-04\n",
            "Epoch 32/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0364 - val_accuracy: 0.9955 - lr: 3.8742e-04\n",
            "Epoch 33/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0289 - val_accuracy: 0.9952 - lr: 3.8742e-04\n",
            "Epoch 34/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0320 - val_accuracy: 0.9956 - lr: 3.4868e-04\n",
            "Epoch 35/70\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0261 - val_accuracy: 0.9957 - lr: 3.4868e-04\n",
            "Epoch 36/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0309 - val_accuracy: 0.9956 - lr: 3.1381e-04\n",
            "Epoch 37/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0265 - val_accuracy: 0.9958 - lr: 3.1381e-04\n",
            "Epoch 38/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0247 - val_accuracy: 0.9957 - lr: 2.8243e-04\n",
            "Epoch 39/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 9.6899e-04 - accuracy: 0.9996 - val_loss: 0.0268 - val_accuracy: 0.9963 - lr: 2.8243e-04\n",
            "Epoch 40/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 7.3537e-04 - accuracy: 0.9998 - val_loss: 0.0262 - val_accuracy: 0.9960 - lr: 2.5419e-04\n",
            "Epoch 41/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 7.8378e-04 - accuracy: 0.9998 - val_loss: 0.0297 - val_accuracy: 0.9955 - lr: 2.5419e-04\n",
            "Epoch 42/70\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 9.8509e-04 - accuracy: 0.9997 - val_loss: 0.0296 - val_accuracy: 0.9959 - lr: 2.2877e-04\n",
            "Epoch 43/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0298 - val_accuracy: 0.9961 - lr: 2.2877e-04\n",
            "Epoch 44/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0263 - val_accuracy: 0.9962 - lr: 2.0589e-04\n",
            "Epoch 45/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 8.8144e-04 - accuracy: 0.9997 - val_loss: 0.0335 - val_accuracy: 0.9956 - lr: 2.0589e-04\n",
            "Epoch 46/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 7.5928e-04 - accuracy: 0.9998 - val_loss: 0.0286 - val_accuracy: 0.9962 - lr: 1.8530e-04\n",
            "Epoch 47/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0263 - val_accuracy: 0.9965 - lr: 1.8530e-04\n",
            "Epoch 48/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0301 - val_accuracy: 0.9961 - lr: 1.8530e-04\n",
            "Epoch 49/70\n",
            "469/469 [==============================] - 35s 74ms/step - loss: 5.5834e-04 - accuracy: 0.9998 - val_loss: 0.0295 - val_accuracy: 0.9958 - lr: 1.8530e-04\n",
            "Epoch 50/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 5.8692e-04 - accuracy: 0.9999 - val_loss: 0.0313 - val_accuracy: 0.9963 - lr: 1.6677e-04\n",
            "Epoch 51/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 8.3933e-04 - accuracy: 0.9997 - val_loss: 0.0332 - val_accuracy: 0.9959 - lr: 1.6677e-04\n",
            "Epoch 52/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 5.2578e-04 - accuracy: 0.9999 - val_loss: 0.0357 - val_accuracy: 0.9961 - lr: 1.5009e-04\n",
            "Epoch 53/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0318 - val_accuracy: 0.9961 - lr: 1.5009e-04\n",
            "Epoch 54/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 3.7347e-04 - accuracy: 0.9999 - val_loss: 0.0321 - val_accuracy: 0.9962 - lr: 1.3509e-04\n",
            "Epoch 55/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 6.3278e-04 - accuracy: 0.9998 - val_loss: 0.0328 - val_accuracy: 0.9957 - lr: 1.3509e-04\n",
            "Epoch 56/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 5.7445e-04 - accuracy: 0.9998 - val_loss: 0.0356 - val_accuracy: 0.9962 - lr: 1.2158e-04\n",
            "Epoch 57/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 8.4480e-04 - accuracy: 0.9998 - val_loss: 0.0311 - val_accuracy: 0.9964 - lr: 1.2158e-04\n",
            "Epoch 58/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 1.2518e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9961 - lr: 1.0942e-04\n",
            "Epoch 59/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 4.3103e-04 - accuracy: 0.9998 - val_loss: 0.0325 - val_accuracy: 0.9956 - lr: 1.0942e-04\n",
            "Epoch 60/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 2.5495e-04 - accuracy: 0.9999 - val_loss: 0.0348 - val_accuracy: 0.9961 - lr: 9.8477e-05\n",
            "Epoch 61/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 2.5986e-04 - accuracy: 0.9999 - val_loss: 0.0373 - val_accuracy: 0.9963 - lr: 9.8477e-05\n",
            "Epoch 62/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 4.3759e-04 - accuracy: 0.9998 - val_loss: 0.0339 - val_accuracy: 0.9963 - lr: 8.8629e-05\n",
            "Epoch 63/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 3.6341e-04 - accuracy: 0.9998 - val_loss: 0.0338 - val_accuracy: 0.9963 - lr: 8.8629e-05\n",
            "Epoch 64/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 5.1119e-04 - accuracy: 0.9999 - val_loss: 0.0323 - val_accuracy: 0.9962 - lr: 7.9766e-05\n",
            "Epoch 65/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 2.3290e-04 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9961 - lr: 7.9766e-05\n",
            "Epoch 66/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 9.9669e-05 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9964 - lr: 7.1790e-05\n",
            "Epoch 67/70\n",
            "469/469 [==============================] - 34s 73ms/step - loss: 2.5342e-04 - accuracy: 0.9999 - val_loss: 0.0344 - val_accuracy: 0.9966 - lr: 7.1790e-05\n",
            "Epoch 68/70\n",
            "469/469 [==============================] - 34s 73ms/step - loss: 2.1704e-04 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9964 - lr: 6.4611e-05\n",
            "Epoch 69/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 3.9555e-04 - accuracy: 0.9999 - val_loss: 0.0346 - val_accuracy: 0.9964 - lr: 6.4611e-05\n",
            "Epoch 70/70\n",
            "469/469 [==============================] - 34s 72ms/step - loss: 3.5373e-04 - accuracy: 0.9999 - val_loss: 0.0331 - val_accuracy: 0.9966 - lr: 5.8150e-05\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0331 - accuracy: 0.9966\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03309451416134834, 0.9965999722480774]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "digitrecognition",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}